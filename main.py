"""
ä¸»ç¨‹åº - åˆ†å­æ´»æ€§é¢„æµ‹æœºå™¨å­¦ä¹ é¡¹ç›®
"""
import sys
import os
import time
import logging
from datetime import datetime
from data_loader import DataLoader
from model_factory import ModelFactory
from model_evaluator import ModelEvaluator
from visualizer import Visualizer
from config import Config

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(Config.OUTPUT_DIR, exist_ok=True)
    
    # è®¾ç½®æ—¥å¿—æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(Config.OUTPUT_DIR, f"experiment_log_{timestamp}.log")
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return log_file

def print_header():
    """æ‰“å°é¡¹ç›®å¤´éƒ¨ä¿¡æ¯"""
    print("=" * 60)
    print("åˆ†å­æ´»æ€§é¢„æµ‹æœºå™¨å­¦ä¹ é¡¹ç›®")
    print(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

def print_config_info():
    """æ‰“å°é…ç½®ä¿¡æ¯"""
    print("\nğŸ“‹ é¡¹ç›®é…ç½®ä¿¡æ¯:")
    print(f"  æ•°æ®æ–‡ä»¶: {Config.DATA_PATH}")
    print(f"  éšæœºç§å­: {Config.RANDOM_STATE}")
    print(f"  æµ‹è¯•é›†æ¯”ä¾‹: {Config.TEST_SIZE}")
    print(f"  äº¤å‰éªŒè¯æŠ˜æ•°: {Config.N_FOLDS}")
    print(f"  è¾“å‡ºç›®å½•: {Config.OUTPUT_DIR}")

def print_data_info(df, fingerprints, labels):
    """æ‰“å°æ•°æ®ä¿¡æ¯"""
    print(f"\nğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(df)}")
    
    # å¤„ç†ä¸åŒç±»å‹çš„fingerprintsæ•°æ®
    if hasattr(fingerprints, 'shape'):
        # NumPyæ•°ç»„æˆ–ç±»ä¼¼å¯¹è±¡
        print(f"  ç‰¹å¾ç»´åº¦: {fingerprints.shape[1]}")
    elif isinstance(fingerprints, list) and len(fingerprints) > 0:
        # åˆ—è¡¨ç±»å‹
        if isinstance(fingerprints[0], (list, tuple)):
            print(f"  ç‰¹å¾ç»´åº¦: {len(fingerprints[0])}")
        else:
            print(f"  ç‰¹å¾ç»´åº¦: æœªçŸ¥ (ä¸€ç»´æ•°æ®)")
    else:
        print(f"  ç‰¹å¾ç»´åº¦: æœªçŸ¥")
    
    print(f"  æ´»æ€§åŒ–åˆç‰©: {sum(labels)} ({sum(labels)/len(labels)*100:.1f}%)")
    print(f"  éæ´»æ€§åŒ–åˆç‰©: {len(labels)-sum(labels)} ({(len(labels)-sum(labels))/len(labels)*100:.1f}%)")

def print_model_info(models):
    """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
    print(f"\nğŸ¤– åˆ›å»ºäº† {len(models)} ä¸ªæ¨¡å‹:")
    for i, model in enumerate(models, 1):
        print(f"  {i}. {model['name']} ({model['label']})")

def print_performance_summary(performance_results):
    """æ‰“å°æ€§èƒ½æ±‡æ€»"""
    print("\nğŸ“ˆ æ¨¡å‹æ€§èƒ½æ±‡æ€»:")
    print("-" * 80)
    print(f"{'æ¨¡å‹':<20} {'å‡†ç¡®ç‡':<10} {'æ•æ„Ÿæ€§':<10} {'ç‰¹å¼‚æ€§':<10} {'AUC':<10} {'æ’å':<6}")
    print("-" * 80)
    
    # æŒ‰AUCæ’åº
    sorted_results = sorted(performance_results.items(), key=lambda x: x[1][3], reverse=True)
    
    for rank, (label, (acc, sens, spec, auc)) in enumerate(sorted_results, 1):
        model_name = label.replace('Model_', '')
        print(f"{model_name:<20} {acc:<10.4f} {sens:<10.4f} {spec:<10.4f} {auc:<10.4f} #{rank}")
    
    print("-" * 80)
    
    # æœ€ä½³æ¨¡å‹
    best_model = sorted_results[0]
    print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model[0].replace('Model_', '')} (AUC: {best_model[1][3]:.4f})")

def save_results(performance_results, log_file):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    results_file = os.path.join(Config.OUTPUT_DIR, "model_results.txt")
    
    with open(results_file, 'w', encoding='utf-8') as f:
        f.write("åˆ†å­æ´»æ€§é¢„æµ‹æœºå™¨å­¦ä¹ é¡¹ç›® - ç»“æœæ±‡æ€»\n")
        f.write("=" * 60 + "\n")
        f.write(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"é…ç½®ä¿¡æ¯:\n")
        f.write(f"  - æ•°æ®æ–‡ä»¶: {Config.DATA_PATH}\n")
        f.write(f"  - éšæœºç§å­: {Config.RANDOM_STATE}\n")
        f.write(f"  - æµ‹è¯•é›†æ¯”ä¾‹: {Config.TEST_SIZE}\n")
        f.write(f"  - äº¤å‰éªŒè¯æŠ˜æ•°: {Config.N_FOLDS}\n\n")
        
        f.write("æ¨¡å‹æ€§èƒ½ç»“æœ:\n")
        f.write("-" * 60 + "\n")
        f.write(f"{'æ¨¡å‹':<20} {'å‡†ç¡®ç‡':<10} {'æ•æ„Ÿæ€§':<10} {'ç‰¹å¼‚æ€§':<10} {'AUC':<10}\n")
        f.write("-" * 60 + "\n")
        
        # æŒ‰AUCæ’åº
        sorted_results = sorted(performance_results.items(), key=lambda x: x[1][3], reverse=True)
        
        for label, (acc, sens, spec, auc) in sorted_results:
            model_name = label.replace('Model_', '')
            f.write(f"{model_name:<20} {acc:<10.4f} {sens:<10.4f} {spec:<10.4f} {auc:<10.4f}\n")
        
        f.write("-" * 60 + "\n")
        best_model = sorted_results[0]
        f.write(f"æœ€ä½³æ¨¡å‹: {best_model[0].replace('Model_', '')} (AUC: {best_model[1][3]:.4f})\n")
    
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³: {results_file}")

def main():
    """ä¸»å‡½æ•°"""
    start_time = time.time()
    
    try:
        # è®¾ç½®æ—¥å¿—
        log_file = setup_logging()
        
        # æ‰“å°é¡¹ç›®ä¿¡æ¯
        print_header()
        print_config_info()
        
        logging.info("å¼€å§‹æ‰§è¡Œåˆ†å­æ´»æ€§é¢„æµ‹æœºå™¨å­¦ä¹ é¡¹ç›®")
        
        # 1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        print("\nğŸ”„ 1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†...")
        logging.info("å¼€å§‹æ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
        
        data_loader = DataLoader()
        df = data_loader.load_and_preprocess()
        
        # 2. å‡†å¤‡æ¨¡å‹æ•°æ®
        print("\nğŸ”„ 2. å‡†å¤‡æ¨¡å‹æ•°æ®...")
        logging.info("å‡†å¤‡æ¨¡å‹æ•°æ®")
        
        fingerprints, labels = data_loader.prepare_model_data()
        print_data_info(df, fingerprints, labels)
        
        # 3. æ‹†åˆ†æ•°æ®é›†
        print("\nğŸ”„ 3. æ‹†åˆ†æ•°æ®é›†...")
        logging.info("æ‹†åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†")
        
        train_x, test_x, train_y, test_y = data_loader.split_data(fingerprints, labels)
        splits = [train_x, test_x, train_y, test_y]
        
        print(f"  è®­ç»ƒé›†: {len(train_x)} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {len(test_x)} æ ·æœ¬")
        
        # 4. åˆ›å»ºæ¨¡å‹
        print("\nğŸ”„ 4. åˆ›å»ºæ¨¡å‹...")
        logging.info("åˆ›å»ºæœºå™¨å­¦ä¹ æ¨¡å‹")
        
        models = ModelFactory.create_all_models()
        print_model_info(models)
        
        # 5. æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯
        print("\nğŸ”„ 5. æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯...")
        logging.info("å¼€å§‹æ¨¡å‹è®­ç»ƒå’ŒéªŒè¯")
        
        performance_results = {}
        
        for i, model_info in enumerate(models, 1):
            print(f"\n--- è®­ç»ƒæ¨¡å‹ {i}/{len(models)}: {model_info['name']} ---")
            logging.info(f"è®­ç»ƒæ¨¡å‹: {model_info['name']}")
            
            model = model_info['model']
            label = model_info['label']
            
            # è®­ç»ƒå’ŒéªŒè¯
            accuracy, sensitivity, specificity, auc = ModelEvaluator.train_and_validate(
                model, label, splits, verbose=True
            )
            
            # å­˜å‚¨ç»“æœ
            performance_results[label] = (accuracy, sensitivity, specificity, auc)
            
            print(f"âœ… {model_info['name']} è®­ç»ƒå®Œæˆ (AUC: {auc:.4f})")
        
        # 6. äº¤å‰éªŒè¯
        print("\nğŸ”„ 6. äº¤å‰éªŒè¯...")
        logging.info("å¼€å§‹äº¤å‰éªŒè¯")
        
        for model_info in models:
            print(f"\n======= {model_info['label']} äº¤å‰éªŒè¯ =======")
            logging.info(f"äº¤å‰éªŒè¯: {model_info['name']}")
            
            ModelEvaluator.cross_validation(
                model_info['model'], df, n_folds=Config.N_FOLDS
            )
        
        # 7. å¯è§†åŒ–
        print("\nğŸ”„ 7. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        logging.info("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
        
        visualizer = Visualizer()
        
        # ç»˜åˆ¶ROCæ›²çº¿
        print("  ğŸ“Š ç»˜åˆ¶ROCæ›²çº¿...")
        roc_fig = visualizer.plot_roc_curves(models, test_x, test_y, save_png=True)
        
        # ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾
        print("  ğŸ“Š ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾...")
        performance_fig = visualizer.plot_performance_comparison(
            performance_results, save_png=True
        )
        
        # 8. è¾“å‡ºæ€»ç»“
        print("\nğŸ”„ 8. é¡¹ç›®æ€»ç»“...")
        logging.info("ç”Ÿæˆé¡¹ç›®æ€»ç»“")
        
        print_performance_summary(performance_results)
        
        # ä¿å­˜ç»“æœ
        save_results(performance_results, log_file)
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        end_time = time.time()
        execution_time = end_time - start_time
        
        print("\n" + "=" * 60)
        print("âœ… é¡¹ç›®æ‰§è¡Œå®Œæˆï¼")
        print(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {Config.OUTPUT_DIR}")
        print(f"ğŸ“‹ æ—¥å¿—æ–‡ä»¶: {log_file}")
        print("=" * 60)
        
        logging.info(f"é¡¹ç›®æ‰§è¡Œå®Œæˆï¼Œæ€»è€—æ—¶: {execution_time:.2f} ç§’")
        
        # æ˜¾ç¤ºå›¾è¡¨
        print("\nğŸ“Š æ˜¾ç¤ºå›¾è¡¨...")
        visualizer.show_plots()
        
    except FileNotFoundError as e:
        error_msg = f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ° - {Config.DATA_PATH}"
        print(f"âŒ é”™è¯¯: {error_msg}")
        print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        logging.error(error_msg)
        sys.exit(1)
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        logging.info("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(0)
        
    except Exception as e:
        error_msg = f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(f"âŒ {error_msg}")
        logging.error(error_msg)
        import traceback
        traceback.print_exc()
        logging.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()